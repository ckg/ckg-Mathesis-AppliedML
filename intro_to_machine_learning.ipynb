{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Μια (Πολύ Μικρή) Εισαγωγή στη Μηχανική Μάθηση\n",
    "\n",
    "* Περιέχει υλικό από το κεφάλαιο 5 του βιβλίου του Jake VanderPlas [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html). \n",
    "\n",
    "---\n",
    "\n",
    "> Πάνος Λουρίδας, Αναπληρωτής Καθηγητής <br />\n",
    "> Τμήμα Διοικητικής Επιστήμης και Τεχνολογίας <br />\n",
    "> Οικονομικό Πανεπιστήμιο Αθηνών <br />\n",
    "> louridas@aueb.gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* H Wikipedia δίνει [ως ορισμό της Μηχανικής Μάθησης (Machine learning)](https://en.wikipedia.org/wiki/Machine_learning) τη μελέτη αλγορίθμων που μπορούν να βελτιώνονται αυτομάτως μέσω εμπειρίας και χρήσης δεδομένων.\n",
    "\n",
    "* Μπορεί να διαχωριστεί σε τρία είδη:\n",
    "    * Επιτηρούμενη ή επιβλεπόμενη μάθηση (supervised learning).\n",
    "    * Μη επιτηρούμενη ή μη επιβλεπόμενη μάθηση (unsupervised learning).\n",
    "    * Ενισχυτική μάθηση (reinforcement learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Στην επιτηρούμενη μάθηση, δίνουμε στον υπολογιστή ένα σύνολο προβλημάτων *μαζί με τις λύσεις τους*.\n",
    "\n",
    "* Στη φάση της *εκπαίδευσης* (training) ο υπολογιστής θα καταφέρει (ελπίζουμε) να βρει τον τρόπο ώστε από ένα πρόβλημα να φτάνει στη λύση του.\n",
    "\n",
    "* Η επιτήρηση έγκειται στο ότι ο υπολογιστής έχει ένα μπούσουλα: το λυσάρι.\n",
    "\n",
    "* Αφού τελειώσει η εκπαίδευση, θέλουμε να ελέγξουμε πόσο καλά έχει μάθει ο υπολογιστής από τα δεδομένα που του δώσαμε.\n",
    "\n",
    "* Αυτό το κάνουμε στη φάση του *ελέγχου* (testing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Τυπικές εφαρμογές είναι:\n",
    "\n",
    "  * Ταξινόμηση (classification).\n",
    "  * Παλινδρόμηση (regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Στην μη επιτηρούμενη μάθηση, δίνουμε στον υπολογιστή μόνο ένα σύνολο προβλημάτων, χωρίς λύσεις.\n",
    "\n",
    "* Τυπικές εφαρμογές:\n",
    "\n",
    "  * Συσταδοποίηση (clustering).\n",
    "  * Μείωση διαστασιμότητας (dimensionality reduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Στην ενισχυτική μάθηση, ο υπολογιστής αλληλεπιδρά με κάποιον τρόπο με το περιβάλλον του, λαμβάνοντας έτσι ανατροφοδότηση (feedback) στη συμπεριφορά που επιδεικνύει.\n",
    "\n",
    "* Όταν η συμπεριφορά είναι ορθή, δίνεται επιβράβευση, διαφορετικά επιβάλλεται κάποιου είδους ποινή.\n",
    "\n",
    "* Τυπικές εφαρμογές είναι αυτόνομα συστήματα όπως οχήματα χωρίς οδηγό, ρομπότ, κ.λπ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Έστω ότι έχουμε δεδομένα με δύο ιδιότητες, ή διαστάσεις, τα οποία ανήκουν σε δύο διαφορετικές κατηγορίες, ή κλάσεις. \n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Θέλουμε να βρούμε έναν τρόπο ώστε για οποιοδήποτε σημείο  $(x, y)$ να μπορούμε να προβλέψουμε αν ανήκει στην κλάση 0 ή στην κλάση 1.\n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes_classify_x.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Αυτό μπορούμε να το κάνουμε χωρίζοντας το επίπεδο στα δύο με μία γραμμή.\n",
    "\n",
    "* Ιδού τρεις υποψήφιες γραμμές."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Πράγματι, αν τις ζωγραφίσουμε, θα δούμε ότι και οι τρεις μπορούν να κάνουν τη δουλειά μας.\n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes_three_classifiers.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Το ερώτημα τότε είναι, ποια θα επιλέξουμε;\n",
    "\n",
    "* Ορίζουμε ως *περιθώριο* (margin) την ελάχιστη απόσταση μιας γραμμής από τα δεδομένα μας."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Ιδού το περιθώριο γύρω από κάθε γραμμή.\n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes_three_classifiers_margins.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Τότε η απάντηση στο πρόβλημά μας είναι: επιλέγουμε τη γραμμή εκείνη με το μέγιστο δυνατό περιθώριο.\n",
    "\n",
    "* Γι' αυτό ο ταξινομητής μας ονομάζεται *Ταξινομητής Μέγιστου Περιθωρίου* (Maximal Margin Classifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Στο παράδειγμά μας είναι η πρώτη από τις τρεις γραμμές που ζωγραφίσαμε.\n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes_classifier_margin.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Επομένως η λύση στο πρόβλημά μας είναι η γραμμή:\n",
    "\n",
    "$$ y = 0{,}17 x + 2{,}32 $$\n",
    "\n",
    "* Ξέρουμε ότι μια γραμμή περιγράφεται από την παράσταση:\n",
    "\n",
    "$$ y = ax + b $$\n",
    "\n",
    "* Η μάθηση στη συγκεκριμένη περίπτωση έγκειται στην εύρεση των δύο παραμέτρων $a = 0{,}17$ και $b = 2{,}32$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Αν το σκεφτούμε λίγο, η γραμμή ορίζεται μόνο από τα σημεία που είναι εγγύτερα σε αυτήν.\n",
    "\n",
    "* Τα υπόλοιπα σημεία δεν έχουν στην πραγματικότητα σημασία.\n",
    "\n",
    "* Τα σημεία τα οποία ορίζουν τη γραμμή ονομάζονται *διανύσματα στήριξης* (support vectors).\n",
    "\n",
    "* Είναι τα σημεία τα οποία εφάπτονται στο περιθώριο."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Ας δούμε τα διανύσματα στήριξης στην περίπτωσή μας:\n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes_classifier_support_vectors.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Για να δούμε λίγο που βρισκόμαστε.\n",
    "\n",
    "* Θέλουμε έναν τρόπο να βρούμε, δηλαδή να *μάθουμε*, τη γραμμή που χωρίζει τις δύο κλάσεις με τον βέλτιστο τρόπο.\n",
    "\n",
    "* Δηλαδή πρέπει να μάθουμε ποια είναι η γραμμή με το μέγιστο περιθώριο.\n",
    "\n",
    "* Πώς το βρίσκουμε; Όχι δοκιμάζοντας γραμμούλες: υπάρχει συγκεκριμένος αλγόριθμος που με βάση τα δεδομένα που του δίνουμε εντοπίζει ποια είναι η βέλτιστη γραμμή."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Βεβαίως, τα δεδομένα μας δεν έχουν απαραιτήτως μόνο δύο χαρακτηριστικά (διαστάσεις).\n",
    "\n",
    "* Τις περισσότερες φορές θα έχουν αρκετά περισσότερα.\n",
    "\n",
    "* Ισχύει όμως το ίδιο και στις περισσότερες διαστάσεις."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Αν τα δεδομένα μας έχουν τρία χαρακτηριστικά, ιδιότητες, διαστάσεις, τότε για να τα διαχωρίσουμε πρέπει να βρούμε ένα *επίπεδο*.\n",
    "\n",
    "* Αν τα δεδομένα μας έχουν περισσότερα από τρία χαρακτηριστικά, ιδιότητες, διαστάσεις, τότε για να τα διαχωρίσουμε πρέπει να βρούμε τη γενίκευση του επιπέδου, που ονομάζεται *υπερεπίπεδο* (hypeplane).\n",
    "\n",
    "* Αυτό μπορεί να γίνει αποτελεσματικά μέσω αλγορίθμου, όπως και στην περίπτωση της γραμμής."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Ας προσθέσουμε τώρα στα δεδομένα μας μια παρατήρηση της κλάσης 0 στη θέση $(0, 2)$.\n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes_classifier_extra_point.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Τότε η γραμμή που είχαμε βρει προηγουμένως δεν διαχωρίζει πλέον τα δεδομένα μας πλήρως σε δύο κλάσεις.\n",
    "\n",
    "* Ο βέλτιστος ταξινομητής τώρα είναι η γραμμή:\n",
    "\n",
    "$$ y = 0{,}61 x  + 1{,}34$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Αν ζωγραφίσουμε τη νέα γραμμή με μαύρο και την προηγούμενη με πράσινο, μπορούμε να συνειδητοποιήσουμε την αλλαγή που επέφερε μία και μόνη παρατήρηση.\n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes_classifier_extra_point_updated.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Θέλουμε όμως πράγματι κάτι τέτοιο;\n",
    "\n",
    "* Θέλουμε η λύση στο πρόβλημά μας να είναι τόσο ευαίσθητη σε μικρές αλλαγές;\n",
    "\n",
    "* Αυτό δεν είναι και τόσο καλή ιδέα.\n",
    "\n",
    "* Μπορεί να προτιμούμε να αφήσουμε λίγο λάσκα: να επιτρέψουμε σε κάποιες παρατηρήσεις να παραβιάσουν το περιθώριο, ακόμα και το υπερεπίπεδο, ώστε η λύση μας να είναι πιο ανθεκτική, για παράδειγμα σε έκτοπες τιμές.\n",
    "\n",
    "* Αλλά θα θέλαμε να ελέγξουμε αυτή τη λάσκα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Πραγματικά, αν χαλαρώσουμε έτσι κάπως τον αλγόριθμο, θα βρει μια άλλη γραμμή, η οποία ταξινομεί μεν λάθος το νέο σημείο, αλλά μπορεί αυτό να το θεωρούμε αποδεκτό:\n",
    "\n",
    "$$ y = 0{,}37 x + 2{,}13 $$\n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes_sv_classifier.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Ο νέος προσαρμοσμένος αλγόριθμος ονομάζεται Ταξινομητής Διανυσμάτων Στήριξης (Support Vector Classifier).\n",
    "\n",
    "* Το ευχάριστο είναι ότι και με αυτόν μπορούμε να μάθουμε πολύ αποτελεσματικά τον διαχωριστή των κλάσεών μας.\n",
    "\n",
    "* Επιπλέον, στον αλγόριθμο αυτό δίνουμε ως παράμετρο, όχι μόνο τα δεδομένα μας που πρέπει να διαχωριστούν, αλλά και το πόσο χαλαρός θέλουμε να είναι στην τήρηση του περιθωρίου.\n",
    "\n",
    "* Στη Μηχανική Μάθηση, οι παράμετροι οι οποίοι ρυθμίζουν τη λειτουργία ενός αλγορίθμου ονομάζονται *υπερπαράμετροι* (hyperparameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Ας δούμε τώρα ένα διαφορετικό σύνολο δεδομένων.\n",
    "\n",
    "* Σε αντίθεση με το προηγούμενο, τα δεδομένα αυτά δεν είναι *γραμμικώς διαχωρίσιμα* (linearly separable).\n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes_nlseparable.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Αυτό σημαίνει ότι δεν μπορούμε να βρούμε μια ευθεία γραμμή που να τα διαχωρίζει.\n",
    "\n",
    "* Βεβαίως το ίδιο μπορεί να συμβαίνει και σε περισσότερες διαστάσεις, όπου δεν θα μπορούμε να βρούμε ένα υπερεπίπεδο που να διαχωρίζει τα δεδομένα μας."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Μπορούμε όμως να προβάλουμε τα δεδομένα μας σε παραπάνω διαστάσεις, όπου εκεί ελπίζουμε να είναι γραμμικώς διαχωρίσιμα από ένα υπερεπίπεδο.\n",
    "\n",
    "* Μπορούμε να προσθέσουμε μια τρίτη διάσταση $z$ χρησιμοποιώντας τη συνάρτηση:\n",
    "\n",
    "$$ z = e^{-(x^2 + y^2)} $$\n",
    "\n",
    "* Τα σημεία κοντά στο $(0, 0)$ θα έχουν τιμή $z$ κοντά στο 1, ενώ τα σημεία στην περιφέρεια θα έχουν χαμηλότερες τιμές $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Πράγματι, μπορούμε να το διαπιστώσουμε αυτό στην παρακάτω τρισδιάστατη απεικόνιση:\n",
    "<img src=\"two_classes_nlseparable_3d.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Αφού βρούμε το διαχωριστή επίπεδο στις τρεις διαστάσεις, μπορούμε να επιστρέψουμε στις δύο διαστάσεις και να δούμε την ταξινόμηση των δεδομένων:\n",
    "\n",
    "<img src=\"data/two_classes_1/two_classes_nlseparable_2d.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Η γενίκευση των Ταξινομητών Διανυσμάτων Στήριξης ονομάζεται Μηχανή Διανυσμάτων Στήριξης (Support Vector Machine).\n",
    "\n",
    "* Οι ερευνητές έχουν βρει συναρτήσεις, όπως η εκθετική που χρησιμοποιήσαμε, που έχουν καλά αποτελέσματα για τον χειρισμό μη γραμμικώς διαχωρίσιμων δεδομένων.\n",
    "\n",
    "* Οι συναρτήσεις αυτές ονομάζονται *συναρτήσεις πυρήνα* (kernel functions).\n",
    "\n",
    "* Συνοψίζοντας, με τις Μηχανές Διανυσμάτων Στήριξης έχουμε έναν μηχανισμό με τον οποίο ο υπολογιστής μπορεί να μάθει, από τα παραδείγματα που του δίνουμε, να διαχωρίζει τα δεδομένα σε δύο διαφορετικές κλάσεις.\n",
    "\n",
    "* Και με αυτά, μπορούμε να δούμε πώς δουλεύουν οι Μηχανές Διανυσμάτων Στήριξης στην πράξη."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
